{

  "work": [
    {
      "company": "DSCI",
      "website": "https://dsci.com",
      "position": "Programmer",
      "startDate": "2007-09",
      "endDate": "2011-04",
      "summary": "Defense and Aerospace development.",
      "highlights": [
        "Managed small team on two projects. I fulfilled small-scale managerial roles on contract development.",
        "Assisted with composing and delivering bids for contracts.",
        "Presented deliverables to clients or potential clients.",
        "Conducted site visits and site surveys to assess problems and discover solutions."
      ],
      "projects": [
        {
          "title": "MILES CVS Tracer",
          "startDate": "2007-09","noEndDate": true,
          "summary":"Two years full development cycle for proprietary hardware targeting Texas Instruments’ DaVinci DVEVM6446 on an embedded Linux system utilizing both CPU and DSP which was designed, implemented, debugged and maintained during the scope of the project.   This project targeted the MILES-CVS force-on-force combat exercise system.  My company designed and developed a hardware device to inject visual tracers into both the optical and digital video path of the vehicle gunner and commander.  This solution was to resolve an absence in realism when conducting field exercises when the gunner would not receive sensory feedback from firing the laser-modification of the weapon systems.  I served as lead software engineer.  The hardware consisted of five TI DaVinci chips that demanded a multi-processor software architecture.  My system communicated inter-processor and distributed tasks accordingly to CPU load and processor scope and responsibility.  The TI DaVinci chip also contained a DSP and I had to port an OpenGL ES implementation to run on the DSP asynchronously from the CPU to lower the resource usage of the CPU.  I also modified the graphics implementation to natively support the DaVinci architecture. Besides developing the graphical representation of the munitions that were fired, I was responsible for traveling to sites and acquiring data from and resolving integration matters on the targeted vehicles.  Among these sites were four government military installations and two military vehicle manufacturers, some which were traveled to many times.  During the site visits, I would gather data from vehicle ports; conduct tests to validate data; integrate the current solutions; modify non-working implementations; and troubleshoot any problems that arose.  As vehicle access time was a premium, this continuously challenged me to think critically and create working solutions in a very short order of time. My system had a dependency of another vehicle augment system that was being developed concurrently.  I had to implement procedures and protocols to communicate to that parent system while also maintaining direct communication with current vehicle state. I also created a robust, in-house vehicle simulator in .NET C# to replicate vehicle interactions in the laboratory environment.  This permitted a better use of time when afforded actual vehicle access and prevented pitfalls that were already identified in the lab."
        },
        {
          "title": "StarFACE",
          "startDate": "2009-04","noEndDate": true,
          "summary": "Architected software system in Win32 and C++ that created a scalable, distributed processing network for real-time face recognition and logging.  The desktop application integrated a framework which included PHP and MySQL for backend processing and distribution of results. The software system included an operator application that infers faces in an arbitrary number of agnostic video and image feeds; extracts the facial regions; logs video clips of events; issues work orders that encapsulate the extracted regions to remotely-hosted Master clients; retrieves the results of completed work orders; and presents the results of sightings in a flexible user interface using an intuitive user experience. The Master clients were each in charge of an arbitrary number of Slave clients.  The Masters were aware of current Slave resource usage and Slave resource potential; dictated work orders from the Operator application to underworked Slaves; monitored current performance and dynamically load-balanced work orders; and delivered completed results to the Operator application. The Slave clients received job requests from their Master application.  The Slave was distributed a gallery of images to analyze work orders against; process job requests and issue results back to its Master.  The Slave client was written as a lightweight, portable application intended to be quickly integrated into a variety of machine architectures and operating system types in order to leverage those system’s resource in a cloud computing environment. The Camera Enhancer application was developed to abstract specialized camera interfaces from the Operator.  The Operator application accepts the Camera Enhancer was a network video feed.  The Camera Enhancer can control Pan-Tilt-Zoom cameras, permitting the Operator to programmatically exercise target tracking and persistence.   The Camera Enhancer can also deploy any web cam as a network-enabled video surveillance system for remote extractions and identifications. In support of the distributed recognition environment, I developed a BlackBerry application suite that integrated the mobile device into the distributed processing environment as a producer and a consumer of data content. This included two applications that were written in J2ME.  One application was purposed to enroll new images and videos, that were created by the BlackBerry, as indentified persons in the galleries to recognize against.  The second application would retrieve results after submitting images or videos to detect known persons in the content.  I wrote customized controls to intuitively and optimally present the user with the results within the constraints of a mobile handheld system."
        },
        {
          "title": "Radio Operator Trainer",
          "startDate": "2011-02","noEndDate": true,
          "summary": "Leveraged and modified the Torque game engine to host a computer-based training package which interfaced and communicated with a disjoint Flash application.  The Flash training application was a mature training simulation in its third iteration that required a 3-D environment to engage and entertain the user in a game-like atmosphere while preserving the integrity of the training.  I served as lead engineer to design, modify, and incorporate the independent game engine and coordinate the effort.  I was in charge of two colleagues, assigning priorities; resolving complications; and creating solutions in an agile environment."
        },
        {
          "title": "Radio Protocol Class Generator",
          "startDate": "2008-02","noEndDate": true,
          "summary": "Authored an application that parses plaintext protocol specifications and automatically generated specific compile-ready data classes to handle each protocol subset.  This permitted the rapid deployment of new data processing classes without inundating a data entry operator to keep pace with evolving protocol specifications."
        } ,
        {
          "title": "Model Scene Convertor",
          "startDate": "2010-02","noEndDate": true,
          "summary": "Produced toolset to import and convert COLLADA into proprietary model format.  COLLADA is a growing format specification that is achieving wider popularity and acceptance in many sectors.  This toolset permitted my company to save money by using freely available and appropriately licensed content."
        },
        {
          "title": "Radio Traffic Analyzer",
          "startDate": "2008-02","noEndDate": true,
          "summary": "Developed network datagram analysis toolset that logged protocol activity, visualized captured data, and introduced operations to be enacted upon the data.  This toolset could merge divergent data streams into a resultant protocol stream, extract targeted data, and manipulate multiple fields of the captured data for further analyzing and review.  The newly produced data conformed to standards, resulting in datasets that could successfully be played back in the first-party applications."
        }
      ]
    }
  ]
}